{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ViTalia - Malaria Detection using Vision Transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "______________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Malaria Detection\n",
    "\n",
    "Malaria is a serious and life-threatening disease caused by *Plasmodium* parasites, transmitted to humans through the bites of infected female *Anopheles* mosquitoes. Though malaria is preventable and curable, it remains a major global health concern.\n",
    "\n",
    "- **Global Burden**: In 2017, there were approximately 219 million cases of malaria across 90 countries, leading to around 435,000 deaths. The majority of malaria cases and fatalities occurred in the WHO African Region, which bears 92% of cases and 93% of deaths.\n",
    "- **Affected Populations**: Malaria has a disproportionate impact on children under five and pregnant women, particularly in sub-Saharan Africa. Vulnerable populations in regions with inadequate access to healthcare are at higher risk of severe complications and death.\n",
    "\n",
    "### Understanding Malaria and its Parasites\n",
    "\n",
    "Malaria is caused by *Plasmodium* parasites, which are transmitted through \"malaria vectors\"—infected female *Anopheles* mosquitoes. Five parasite species infect humans, with *P. falciparum* and *P. vivax* posing the greatest risk due to their potential for severe infection and spread.\n",
    "\n",
    "1. **P. falciparum**: The deadliest species, responsible for the majority of malaria-related deaths. Found mainly in sub-Saharan Africa.\n",
    "2. **P. vivax**: Known for causing recurring malaria infections, it is common in Asia and the Americas and poses unique challenges in treatment.\n",
    "\n",
    "### Challenges in Malaria Diagnosis\n",
    "\n",
    "Diagnosing malaria can be complex and challenging, especially in areas where it is no longer endemic. Healthcare providers in these regions may not be accustomed to considering malaria as a potential diagnosis, and laboratory staff may lack experience in identifying the parasites under a microscope. Malaria symptoms—such as fever, chills, and headache—are often mild and easily mistaken for other illnesses, especially in non-immune individuals. Without prompt treatment, *P. falciparum* infections can rapidly progress to severe illness, often within 24 hours, leading to life-threatening complications.\n",
    "\n",
    "### Methods of Malaria Detection\n",
    "\n",
    "#### Microscopic Diagnosis\n",
    "\n",
    "Microscopy remains the gold standard for malaria diagnosis. This involves preparing a blood smear from the patient’s blood, staining it to highlight the parasites, and examining it under a microscope. While highly effective, this method requires high-quality reagents, reliable microscopes, and skilled laboratory staff to detect and differentiate malaria species accurately. Errors can occur if the microscopy equipment or techniques are suboptimal, affecting diagnosis quality.\n",
    "\n",
    "#### Rapid Diagnostic Tests (RDTs)\n",
    "\n",
    "Rapid Diagnostic Tests (RDTs) offer an alternative to microscopy, especially in remote or resource-limited areas. These tests are easy to use, provide quick results, and don’t require extensive training, making them suitable for low-resource settings. However, RDTs can vary in accuracy and may not detect all *Plasmodium* species effectively.\n",
    "\n",
    "#### Molecular Methods\n",
    "\n",
    "Advanced molecular methods like Polymerase Chain Reaction (PCR) provide highly sensitive and specific malaria diagnoses. Although PCR is less common in field settings due to its cost and complexity, it is used in reference laboratories and research settings for identifying parasite species and drug resistance markers. \n",
    "\n",
    "![Malaria](https://cdn1.sph.harvard.edu/wp-content/uploads/2015/03/Malaria-cells_CDC.jpg)\n",
    "\n",
    "### References\n",
    "\n",
    "- [WHO Fact Sheet on Malaria](https://www.who.int/news-room/fact-sheets/detail/malaria)\n",
    "- [CDC Malaria Diagnosis and Treatment](https://www.cdc.gov/malaria/diagnosis_treatment/diagnosis.html)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-01T18:05:05.826941Z",
     "iopub.status.busy": "2024-11-01T18:05:05.826661Z",
     "iopub.status.idle": "2024-11-01T18:43:54.779671Z",
     "shell.execute_reply": "2024-11-01T18:43:54.778547Z",
     "shell.execute_reply.started": "2024-11-01T18:05:05.826911Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a0a02f90fa24587ac29c5b95c7d7b82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/502 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ac4f1402d304ca3a436d8049712600e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/346M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ViTForImageClassification were not initialized from the model checkpoint at google/vit-base-patch16-224-in21k and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5fe5b9522df14ec58fc3406166445c84",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "preprocessor_config.json:   0%|          | 0.00/160 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [1/15]:  82%|████████▏ | 1131/1378 [07:44<01:42,  2.42it/s, loss=0.0125] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error loading image /kaggle/input/cell-images-for-detecting-malaria/cell_images/cell_images/Parasitized/Thumbs.db. Skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [1/15]:  93%|█████████▎| 1285/1378 [08:48<00:38,  2.43it/s, loss=0.0265] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error loading image /kaggle/input/cell-images-for-detecting-malaria/cell_images/cell_images/Uninfected/Thumbs.db. Skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [1/15]: 100%|██████████| 1378/1378 [09:27<00:00,  2.43it/s, loss=0.00759]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/15], Training Loss: 0.1090\n",
      "Epoch [1/15], Validation Loss: 0.0755\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [2/15]:  16%|█▌        | 217/1378 [01:16<06:49,  2.84it/s, loss=0.318]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error loading image /kaggle/input/cell-images-for-detecting-malaria/cell_images/cell_images/Uninfected/Thumbs.db. Skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [2/15]:  56%|█████▌    | 766/1378 [04:31<03:35,  2.84it/s, loss=0.00867]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error loading image /kaggle/input/cell-images-for-detecting-malaria/cell_images/cell_images/Parasitized/Thumbs.db. Skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [2/15]: 100%|██████████| 1378/1378 [08:08<00:00,  2.82it/s, loss=0.00614]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/15], Training Loss: 0.0633\n",
      "Epoch [2/15], Validation Loss: 0.0791\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [3/15]:  74%|███████▍  | 1024/1378 [06:03<02:05,  2.83it/s, loss=0.0256] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error loading image /kaggle/input/cell-images-for-detecting-malaria/cell_images/cell_images/Uninfected/Thumbs.db. Skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [3/15]:  88%|████████▊ | 1208/1378 [07:09<01:00,  2.82it/s, loss=0.0274] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error loading image /kaggle/input/cell-images-for-detecting-malaria/cell_images/cell_images/Parasitized/Thumbs.db. Skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [3/15]: 100%|██████████| 1378/1378 [08:10<00:00,  2.81it/s, loss=0.179]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/15], Training Loss: 0.0403\n",
      "Epoch [3/15], Validation Loss: 0.0765\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [4/15]:  11%|█▏        | 157/1378 [00:56<07:11,  2.83it/s, loss=0.00271]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error loading image /kaggle/input/cell-images-for-detecting-malaria/cell_images/cell_images/Parasitized/Thumbs.db. Skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [4/15]:  85%|████████▍ | 1168/1378 [06:55<01:14,  2.83it/s, loss=0.00304]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error loading image /kaggle/input/cell-images-for-detecting-malaria/cell_images/cell_images/Uninfected/Thumbs.db. Skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [4/15]: 100%|██████████| 1378/1378 [08:10<00:00,  2.81it/s, loss=0.363]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/15], Training Loss: 0.0287\n",
      "Epoch [4/15], Validation Loss: 0.0885\n",
      "Early stopping at epoch 4\n",
      "Test Accuracy: 97.53%\n",
      "Test Precision: 96.92%\n",
      "Test Recall: 98.18%\n",
      "Test F1 Score: 97.55%\n",
      "Confusion Matrix:\n",
      "[[2673   86]\n",
      " [  50 2703]]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms\n",
    "from transformers import ViTForImageClassification, ViTFeatureExtractor\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "from PIL import Image, UnidentifiedImageError\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = ViTForImageClassification.from_pretrained(\"google/vit-base-patch16-224-in21k\", num_labels=2)\n",
    "feature_extractor = ViTFeatureExtractor.from_pretrained(\"google/vit-base-patch16-224-in21k\")\n",
    "\n",
    "model.classifier = torch.nn.Linear(model.classifier.in_features, 2)\n",
    "model.to(device)\n",
    "\n",
    "data_dir = '/kaggle/input/cell-images-for-detecting-malaria/cell_images/cell_images/'\n",
    "\n",
    "class MalariaDataset(Dataset):\n",
    "    def __init__(self, root_dir, feature_extractor, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.feature_extractor = feature_extractor\n",
    "        self.transform = transform\n",
    "        self.image_paths = []\n",
    "        self.labels = []\n",
    "\n",
    "        for label, class_name in enumerate([\"Parasitized\", \"Uninfected\"]):\n",
    "            class_dir = os.path.join(root_dir, class_name)\n",
    "            for img_file in os.listdir(class_dir):\n",
    "                self.image_paths.append(os.path.join(class_dir, img_file))\n",
    "                self.labels.append(label)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_paths[idx]\n",
    "        try:\n",
    "            image = Image.open(img_path).convert(\"RGB\")\n",
    "        except (UnidentifiedImageError, FileNotFoundError):\n",
    "            print(f\"Error loading image {img_path}. Skipping.\")\n",
    "            return self.__getitem__((idx + 1) % len(self)) \n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        label = self.labels[idx]\n",
    "        return image, label\n",
    "\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=feature_extractor.image_mean, std=feature_extractor.image_std)\n",
    "])\n",
    "\n",
    "full_dataset = MalariaDataset(data_dir, feature_extractor, transform=transform)\n",
    "train_size = int(0.8 * len(full_dataset))\n",
    "test_size = len(full_dataset) - train_size\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(full_dataset, [train_size, test_size])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True, pin_memory=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False, pin_memory=True)\n",
    "\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=2e-5)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "num_epochs = 15\n",
    "patience = 3\n",
    "best_val_loss = np.inf\n",
    "early_stop_count = 0\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    progress_bar = tqdm(train_loader, desc=f\"Epoch [{epoch+1}/{num_epochs}]\")\n",
    "\n",
    "    for images, labels in progress_bar:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images).logits\n",
    "        loss = criterion(outputs, labels)\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        progress_bar.set_postfix(loss=loss.item())\n",
    "\n",
    "    avg_train_loss = total_loss / len(train_loader)\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Training Loss: {avg_train_loss:.4f}\")\n",
    "\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images).logits\n",
    "            val_loss += criterion(outputs, labels).item()\n",
    "\n",
    "    avg_val_loss = val_loss / len(test_loader)\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Validation Loss: {avg_val_loss:.4f}\")\n",
    "\n",
    "    if avg_val_loss < best_val_loss:\n",
    "        best_val_loss = avg_val_loss\n",
    "        early_stop_count = 0\n",
    "        torch.save(model.state_dict(), \"best_model.pth\") \n",
    "    else:\n",
    "        early_stop_count += 1\n",
    "        if early_stop_count >= patience:\n",
    "            print(f\"Early stopping at epoch {epoch+1}\")\n",
    "            break\n",
    "\n",
    "model.load_state_dict(torch.load(\"best_model.pth\"))\n",
    "\n",
    "predictions, true_labels = [], []\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images).logits\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        predictions.extend(predicted.cpu().numpy())\n",
    "        true_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "accuracy = accuracy_score(true_labels, predictions)\n",
    "precision = precision_score(true_labels, predictions)\n",
    "recall = recall_score(true_labels, predictions)\n",
    "f1 = f1_score(true_labels, predictions)\n",
    "conf_matrix = confusion_matrix(true_labels, predictions)\n",
    "\n",
    "print(f\"Test Accuracy: {accuracy * 100:.2f}%\")\n",
    "print(f\"Test Precision: {precision * 100:.2f}%\")\n",
    "print(f\"Test Recall: {recall * 100:.2f}%\")\n",
    "print(f\"Test F1 Score: {f1 * 100:.2f}%\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_________________________"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 87153,
     "sourceId": 200743,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30787,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
